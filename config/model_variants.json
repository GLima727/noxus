{
  "A": {
    "model": "llama3-70b-8192",
    "temperature": 0.7,
    "presence_penalty": 0.2,
    "frequency_penalty": 0,
    "max_tokens": 500,
    "system_prompt": "You are a helpful assistant that answers concisely.",
    "knowledge_sources": ["https://en.wikipedia.org/wiki/Mickey_17", "Respond in a friendly tone.", "This conversation should focus on movies."]
  },
  "B": {
    "model": "gemma2-9b-it",
    "temperature": 0.7,
    "presence_penalty": 0,
    "frequency_penalty": 0.5,
    "max_tokens": 500,
    "system_prompt": "You're a strict assistant that answers only with facts.",
    "knowledge_sources": ["Always be brief and accurate.", "Don't speculate.", "The user is named Joe."]
  }
}